{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72841b05-1004-4e13-8495-68c968917ce9",
   "metadata": {},
   "source": [
    "## Importing the Data into Python\n",
    "We'll be using [pandas](https://pandas.pydata.org/docs/user_guide/index.html#user-guide), a data analysis package for python.\n",
    "\n",
    "The first step is to import the package, and use it to import the data as [dataframes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html). Since the data is stored as [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) files, we should use [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas-read-csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27901060-21f5-4fe9-9406-b70e8e591d30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original dataset from the GroupLens Research Project at the University of Minnesota\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7edf2b-99b8-4638-979d-5c1018ab03c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into dataframes\n",
    "df_movies = pd.read_csv(r'./movies.csv')\n",
    "df_metrics = pd.read_csv(r'./metrics.csv')\n",
    "df_ratings = pd.read_csv(r'./ratings_simplified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e8390d",
   "metadata": {},
   "source": [
    "Lets take a look into the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d6c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93004171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49897b9",
   "metadata": {},
   "source": [
    "# Generating the Profile\n",
    "Now, we need to query the client on these movies to generate their profile, lets prompt the client until they provide 10 valid ratings. We need to keep track of the rating, and the movieId. Additionally, we need to ensure that the rating is valid. Lets start be telling\n",
    "the client what we need from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392dcec-d28d-4942-a4bd-a4ae72054b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt client\n",
    "print(\"Hello viewer! Before we can start recommending movies,\")\n",
    "print( \"We need you to rate a few movies to compute your preference profile.\")\n",
    "print( \"Please rate the following movies on a scale of 1 to 10.\")\n",
    "print( \"If you wish to skip rating a movie, press ENTER.\")\n",
    "\n",
    "def prompt_till_valid(movie_title):\n",
    "    client_prompt = \"{}: \".format(movie_title)\n",
    "    while True:\n",
    "        client_response = input(client_prompt)\n",
    "        # skip if necessary\n",
    "        if (client_response == ''):\n",
    "            break\n",
    "        # else, convert input to float\n",
    "        try:\n",
    "            client_response = float(client_response)\n",
    "        except ValueError:\n",
    "            print(\"Sorry, we can only accept numerical ratings\")\n",
    "        else:\n",
    "            # check if rating in 1-10\n",
    "            if (1 <= client_response <= 10):\n",
    "                break\n",
    "            print(\"Sorry, ratings must be between 1 and 10\")\n",
    "    return client_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f80d51",
   "metadata": {},
   "source": [
    "Now, we need to write code that iterates over the movies we have curated, and asks the client to rate them until we have 10 valid ratings. We can do this using the [iterrows](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html) feature for dataframes. Lets store the ratings in a list, and then convert to a dataframe after all the ratings are collected. Use the function given above, to collect the client response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d26ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_ratings = 10\n",
    "df_client = []\n",
    "for index, movie in df_metrics.iterrows():\n",
    "    # call the function\n",
    "    # add to list if valid rating\n",
    "    # stop once we have enough ratings\n",
    "df_client = pd.DataFrame(df_client, columns=['movieId', 'clientRating'])\n",
    "df_client.set_index('movieId', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d433b1",
   "metadata": {},
   "source": [
    "# Computing Cosine Similarity\n",
    "Now, we have enough ratings to start computing the similarity. First, lets create a simplified ratings dataframe to compute the similarity. We can drop ratings of movies that the client has not rated.\n",
    "\n",
    "Additionally, to make sure the similarity scores are accurate, lets only consider users that have rated at least half the movies the client has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc563560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the 10 movieIds from the dictionary\n",
    "client_movies = df_client.index.tolist()\n",
    "# remove ratings of movies not one of those 10\n",
    "df_simple = df_ratings.drop(df_ratings[~df_ratings['movieId'].isin(client_movies)].index)\n",
    "# remove ratings of users that have less than 5 ratings in common\n",
    "df_simple = df_simple[df_simple['userId'].map(df_simple['userId'].value_counts()) >= required_ratings / 2]\n",
    "# merge client ratings\n",
    "df_simple = df_simple.merge(df_client, left_on = 'movieId', right_index = True)\n",
    "df_simple.sort_values('userId', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a409353",
   "metadata": {},
   "source": [
    "Now, lets create a structure to store the similarity between the client and every other user. We can use this to identify the most similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101fe934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique users and add columns to store the magnitude and dot product for each user\n",
    "df_sim = pd.DataFrame(index=df_simple['userId'].unique(), \n",
    "                             columns = ['userMag', 'clientMag', 'dotProd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468a299",
   "metadata": {},
   "source": [
    "$$S(\\text{u, c}) = \\frac{\\sum\\limits_{m \\in M}R(u, m) \\times R(c, m)}{|u| \\times |c|}$$\n",
    "\n",
    "Recalling the formula for calculating cosine similarity, we need to compute user and client magnitudes, as well as pairwise dot products.\n",
    "\n",
    "Of course, to compute these values, the easiest thing would be to go over every rating, and make the necessary update to the specific user. We can compute the squared sum first, and then take the root at the end to obtain the magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the columns with 0\n",
    "df_sim.fillna(0, inplace=True)\n",
    "# for visualization\n",
    "import progressbar\n",
    "n = len(df_simple)\n",
    "bar = progressbar.ProgressBar(maxval=n, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "bar.start()\n",
    "i = 0\n",
    "for index, rating in df_simple.iterrows():\n",
    "    bar.update(i)\n",
    "    i+=1\n",
    "    # update magnitudes and dotprod\n",
    "bar.finish()\n",
    "# take the square root to get the actual magnitudes\n",
    "df_sim['userMag'] = df_sim['userMag'].pow(0.5)\n",
    "df_sim['clientMag'] = df_sim['clientMag'].pow(0.5)\n",
    "# check values\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f24be",
   "metadata": {},
   "source": [
    "Note how inefficient this would become on a larger scale, with 10s of millions of users, and billions of ratings. We can speed up this process by taking advantage of method chaining, and the [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) function. Use the function given below to help you compute the dot product; use the [apply](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.core.groupby.DataFrameGroupBy.apply.html#pandas.core.groupby.DataFrameGroupBy.apply) function to do this. Note that functions chained after grouping must return a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696e273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDotProd(df):\n",
    "    return (df['rating'] * df['clientRating']).sum()\n",
    "# reset the dataframe\n",
    "df_sim = pd.DataFrame(index=df_simple['userId'].unique(), \n",
    "                             columns = ['userMag', 'clientMag', 'dotProd'])\n",
    "# method chain to get the magnitude\n",
    "# use helper function to compute dot product\n",
    "# check values\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fb90f6",
   "metadata": {},
   "source": [
    "Now we have the necessary prerequisites to compute the similarity, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f1944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute similarity and sort users by it (descending)\n",
    "df_sim['similarity'] = np.divide(df_sim['dotProd'], np.multiply(df_sim['userMag'], df_sim['clientMag']))\n",
    "df_sim.sort_values(by='similarity', ascending=False, inplace=True)\n",
    "df_sim\n",
    "# WHY ARE WE KEEPING THE MAGNITUDES AND DOTPROD COLUMNS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41f2b7",
   "metadata": {},
   "source": [
    "Lets plot the similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.reset_index().plot(y='similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21635bd6",
   "metadata": {},
   "source": [
    "# Recommending Movies\n",
    "Now that we have quantified the similarity between the client and users in the database, it is time to recommend movies to the client. Intuitively, you want to recommend movies that similar users have liked. There are a lot of ways of doing this, and the algorithm can be made as complicated as you want. \n",
    "\n",
    "For example, you could, for each movie $m$, compute a score based on every user $u$ that has rated $m$ and that user's similarity with the client $c$.\n",
    "$$score(m) = \\sum\\limits_{u}similarity(c, u)\\times rating(u, m)$$\n",
    "\n",
    "Such functions are called utility/score functions, they are used to quantify sentiments we wish to optimize for. You can take [CSCD84](http://www.cs.utoronto.ca/~strider/LectureNotes.html) if you want to learn more.\n",
    "\n",
    "For now, we're going to use the simple algorithm of filtering users that have a similarity score of less than 0.99. Then, we can compute a weighted average by taking into account the mean rating of a movie based on similar users, and the popularity among similar users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop users below similarity threshold\n",
    "sim_threshold = 0.95\n",
    "df_sim_reduced = df_sim.drop(df_sim[df_sim['similarity'] < sim_threshold].index)\n",
    "df_sim_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c81b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop ratings not given by similar users\n",
    "best_friends = df_sim_reduced.index.tolist()\n",
    "friend_ratings = df_ratings.drop(df_ratings[~df_ratings['userId'].isin(best_friends)].index)\n",
    "# calculate local average and popularity\n",
    "df_mean = friend_ratings.groupby('movieId')['rating'].mean()\n",
    "df_count = friend_ratings.groupby('movieId')['rating'].count()\n",
    "# merge and drop already seen movies\n",
    "df_metrics = pd.concat([df_count, df_mean], axis=1)\n",
    "df_metrics.columns = ['count', 'mean']\n",
    "df_movies.set_index = 'movieId'\n",
    "df_metrics.reset_index(inplace=True)\n",
    "df_metrics = df_metrics.drop(df_metrics[df_metrics['movieId'].isin(client_movies)].index)\n",
    "# get movie titles\n",
    "df_metrics = pd.merge(df_metrics, df_movies, on='movieId', how='left')\n",
    "\n",
    "def scoreMovie(movie, alpha):\n",
    "    return ((1-alpha) * movie['mean']) + (alpha * (movie['count'] / len(best_friends)))\n",
    "df_metrics['score'] = df_metrics.apply(scoreMovie, alpha=0.95, axis=1)\n",
    "# sort by score\n",
    "df_metrics.sort_values('score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
